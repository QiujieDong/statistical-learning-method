{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第7章 Support Vector Machine\n",
    "本章实现SVM代码，最后会调用sklearn.svm.SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "分离超平面：$w^Tx+b=0$\n",
    "\n",
    "点到直线距离：$r=\\frac{|w^Tx+b|}{||w||_2}$\n",
    "\n",
    "$||w||_2$为2-范数：$||w||_2=\\sqrt[2]{\\sum^m_{i=1}w_i^2}$\n",
    "\n",
    "直线为超平面，样本可表示为：\n",
    "\n",
    "$w^Tx+b\\ \\geq+1$\n",
    "\n",
    "$w^Tx+b\\ \\leq-1$\n",
    "\n",
    "#### margin：\n",
    "\n",
    "**函数间隔**：$label(w^Tx+b)\\ or\\ y_i(w^Tx+b)$\n",
    "\n",
    "**几何间隔**：$r=\\frac{y_i(w^Tx+b)}{||w||_2}$，当数据被正确分类时，几何间隔就是点到超平面的距离\n",
    "\n",
    "为了求几何间隔最大，SVM基本问题可以转化为求解:($\\frac{r^*}{||w||}$为几何间隔)，(${r^*}$为函数间隔)\n",
    "\n",
    "$$\\max\\ \\frac{r^*}{||w||}$$\n",
    "\n",
    "$$(subject\\ to)\\ y_i({w^T}x_i+{b})\\geq {r^*},\\ i=1,2,..,m$$\n",
    "\n",
    "分类点几何间隔最大，同时被正确分类。但这个方程并非凸函数求解，所以要先①将方程转化为凸函数，②用拉格朗日乘子法和KKT条件求解对偶问题。\n",
    "\n",
    "①转化为凸函数：\n",
    "\n",
    "先令${r^*}=1$，方便计算（参照衡量，不影响评价结果）\n",
    "\n",
    "$$\\max\\ \\frac{1}{||w||}$$\n",
    "\n",
    "$$s.t.\\ y_i({w^T}x_i+{b})\\geq {1},\\ i=1,2,..,m$$\n",
    "\n",
    "再将$\\max\\ \\frac{1}{||w||}$转化成$\\min\\ \\frac{1}{2}||w||^2$求解凸函数，1/2是为了求导之后方便计算。\n",
    "\n",
    "$$\\min\\ \\frac{1}{2}||w||^2$$\n",
    "\n",
    "$$s.t.\\ y_i(w^Tx_i+b)\\geq 1,\\ i=1,2,..,m$$\n",
    "\n",
    "②用拉格朗日乘子法和KKT条件求解最优值：\n",
    "\n",
    "$$\\min\\ \\frac{1}{2}||w||^2$$\n",
    "\n",
    "$$s.t.\\ -y_i(w^Tx_i+b)+1\\leq 0,\\ i=1,2,..,m$$\n",
    "\n",
    "整合成：\n",
    "\n",
    "$$L(w, b, \\alpha) = \\frac{1}{2}||w||^2+\\sum^m_{i=1}\\alpha_i(-y_i(w^Tx_i+b)+1)$$\n",
    "\n",
    "推导：$\\min\\ f(x)=\\min \\max\\ L(w, b, \\alpha)\\geq \\max \\min\\ L(w, b, \\alpha)$\n",
    "\n",
    "根据KKT条件：\n",
    "\n",
    "$$\\frac{\\partial }{\\partial w}L(w, b, \\alpha)=w-\\sum\\alpha_iy_ix_i=0,\\ w=\\sum\\alpha_iy_ix_i$$\n",
    "\n",
    "$$\\frac{\\partial }{\\partial b}L(w, b, \\alpha)=\\sum\\alpha_iy_i=0$$\n",
    "\n",
    "带入$ L(w, b, \\alpha)$\n",
    "\n",
    "$\\min\\  L(w, b, \\alpha)=\\frac{1}{2}||w||^2+\\sum^m_{i=1}\\alpha_i(-y_i(w^Tx_i+b)+1)$\n",
    "\n",
    "$\\qquad\\qquad\\qquad=\\frac{1}{2}w^Tw-\\sum^m_{i=1}\\alpha_iy_iw^Tx_i-b\\sum^m_{i=1}\\alpha_iy_i+\\sum^m_{i=1}\\alpha_i$\n",
    "\n",
    "$\\qquad\\qquad\\qquad=\\frac{1}{2}w^T\\sum\\alpha_iy_ix_i-\\sum^m_{i=1}\\alpha_iy_iw^Tx_i+\\sum^m_{i=1}\\alpha_i$\n",
    "\n",
    "$\\qquad\\qquad\\qquad=\\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i=1}\\alpha_iy_iw^Tx_i$\n",
    "\n",
    "$\\qquad\\qquad\\qquad=\\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)$\n",
    "\n",
    "再把max问题转成min问题：\n",
    "\n",
    "$\\max\\ \\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)=\\min \\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)-\\sum^m_{i=1}\\alpha_i$\n",
    "\n",
    "$s.t.\\ \\sum^m_{i=1}\\alpha_iy_i=0,$\n",
    "\n",
    "$ \\alpha_i \\geq 0,i=1,2,...,m$\n",
    "\n",
    "以上为SVM对偶问题的对偶形式\n",
    "\n",
    "-----\n",
    "#### kernel\n",
    "\n",
    "在低维空间计算获得高维空间的计算结果，也就是说计算结果满足高维（满足高维，才能说明高维下线性可分）。\n",
    "\n",
    "#### soft margin & slack variable\n",
    "\n",
    "引入松弛变量$\\xi\\geq0$，对应数据点允许偏离的functional margin 的量。\n",
    "\n",
    "目标函数：$\\min\\ \\frac{1}{2}||w||^2+C\\sum\\xi_i\\qquad s.t.\\ y_i(w^Tx_i+b)\\geq1-\\xi_i$ \n",
    "\n",
    "对偶问题：\n",
    "\n",
    "$$\\max\\ \\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)=\\min \\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)-\\sum^m_{i=1}\\alpha_i$$\n",
    "\n",
    "$$s.t.\\ C\\geq\\alpha_i \\geq 0,i=1,2,...,m\\quad \\sum^m_{i=1}\\alpha_iy_i=0,$$\n",
    "\n",
    "-----\n",
    "\n",
    "#### Sequential Minimal Optimization\n",
    "\n",
    "首先定义特征到结果的输出函数：$u=w^Tx+b$.\n",
    "\n",
    "因为$w=\\sum\\alpha_iy_ix_i$\n",
    "\n",
    "有$u=\\sum y_i\\alpha_iK(x_i, x)-b$\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "$\\max \\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i=1}\\sum^m_{j=1}\\alpha_i\\alpha_jy_iy_j<\\phi(x_i)^T,\\phi(x_j)>$\n",
    "\n",
    "$s.t.\\ \\sum^m_{i=1}\\alpha_iy_i=0,$\n",
    "\n",
    "$ \\alpha_i \\geq 0,i=1,2,...,m$\n",
    "\n",
    "-----\n",
    "参考资料：\n",
    "\n",
    "[1] :[Lagrange Multiplier and KKT](http://blog.csdn.net/xianlingmao/article/details/7919597)\n",
    "\n",
    "[2] :[Python实现SVM](http://blog.csdn.net/wds2006sdo/article/details/53156589)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, [0, 1, -1]])\n",
    "    \n",
    "    # set data label to [-1, 1]\n",
    "    data[:, -1] = [1 if d == 1 else -1 for d in data[:, -1]]\n",
    "\n",
    "    return data[:,:2], data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb439844860>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:50, 0], X[:50, 1], label='-1')\n",
    "plt.scatter(X[50:, 0], X[50:, 1], label='1')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, max_iter=100, kernel='linear'):\n",
    "        self.max_iter = max_iter\n",
    "        self._kernel = kernel\n",
    "    \n",
    "    def init_args(self, features, labels):\n",
    "        self.m, self.n = features.shape\n",
    "        self.X = features\n",
    "        self.Y = labels\n",
    "        self.b = 0.0\n",
    "        \n",
    "        # saving Ei to a list\n",
    "        self.alpha = np.ones(self.m)\n",
    "        self.E = [self._E(i) for i in range(self.m)]\n",
    "        # relaxation variable\n",
    "        self.C = 1.0\n",
    "        \n",
    "    def _KKT(self, i):\n",
    "        y_g = self._g(i)*self.Y[i]\n",
    "        if self.alpha[i] == 0:\n",
    "            return y_g >= 1\n",
    "        elif 0 < self.alpha[i] < self.C:\n",
    "            return y_g == 1\n",
    "        else:\n",
    "            return y_g <= 1\n",
    "        \n",
    "    # g(x) is the prediction value. input is xi\n",
    "    def _g(self, i):\n",
    "        r = self.b\n",
    "        for j in range(self.m):\n",
    "            r += self.alpha[j]*self.Y[j]*self.kernel(self.X[i], self.X[j])\n",
    "        return r\n",
    "    \n",
    "    # kernel function\n",
    "    def kernel(self, x1, x2):\n",
    "        if self._kernel == 'linear':\n",
    "            return sum([x1[k]*x2[k] for k in range(self.n)])\n",
    "        elif self._kernel == 'poly':\n",
    "            return (sum([x1[k]*x2[k] for k in range(self.n)]) + 1)**2\n",
    "    \n",
    "        return 0\n",
    "    \n",
    "    # error(x) is the difference between g(x), which is the prediction value of x, and desired output y\n",
    "    def _E(self, i):\n",
    "        return self._g(i) - self.Y[i]\n",
    "    \n",
    "    def _init_alpha(self):\n",
    "        #The outer loop first traverses all sample points that satisfy 0<a<C, and verifies that KKT is satisfied.\n",
    "        index_list = [i for i in range(self.m) if 0 < self.alpha[i] < self.C]\n",
    "        # if not, traversing the entire trainset\n",
    "        non_satisfy_list = [i for i in range(self.m) if i not in index_list]\n",
    "        index_list.extend(non_satisfy_list)\n",
    "        \n",
    "        for i in index_list:\n",
    "            if self._KKT(i):\n",
    "                continue\n",
    "            \n",
    "            E1 = self.E[i]\n",
    "            #if E1 is positive ,selecting the minmun; if E1 is negative, selecting the maximun\n",
    "            if E1 >= 0:\n",
    "                j = min(range(self.m), key=lambda x: self.E[x])\n",
    "            else:\n",
    "                j = max(range(self.m), key=lambda x: self.E[x])\n",
    "            return i, j\n",
    "        \n",
    "    def _compare(self, _alpha, L, H):\n",
    "        if _alpha > H:\n",
    "            return H\n",
    "        elif _alpha < L:\n",
    "            return L\n",
    "        else:\n",
    "            return _alpha\n",
    "        \n",
    "    def fit(self, features, labels):\n",
    "        self.init_args(features, labels)\n",
    "        \n",
    "        for t in range(self.max_iter):\n",
    "            #train\n",
    "            i1, i2 = self._init_alpha()\n",
    "            \n",
    "            #boundary\n",
    "            if self.Y[i1] == self.Y[i2]:\n",
    "                L = max(0, self.alpha[i1]+self.alpha[i2]-self.C)\n",
    "                H = min(self.C, self.alpha[i1]+self.alpha[i2])\n",
    "            else:\n",
    "                L = max(0, self.alpha[i2]-self.alpha[i1])\n",
    "                H = min(self.C, self.C+self.alpha[i2]-self.alpha[i1])\n",
    "                \n",
    "            E1 = self.E[i1]\n",
    "            E2 = self.E[i2]\n",
    "            #eta = K11+k22-2K12\n",
    "            eta = self.kernel(self.X[i1], self.X[i1]) + self.kernel(self.X[i2], self.X[i2]) - 2*self.kernel(self.X[i1], self.X[i2])\n",
    "            if eta <= 0:\n",
    "                continue\n",
    "                \n",
    "            alpha2_new_unc = self.alpha[i2] + self.Y[i2] * (E1 - E2) / eta # E1 - E2 in the book,we change the formula\n",
    "            alpha2_new = self._compare(alpha2_new_unc, L, H)\n",
    "            \n",
    "            alpha1_new = self.alpha[i1] + self.Y[i1] * self.Y[i2] * (self.alpha[i2] - alpha2_new)\n",
    "            \n",
    "            b1_new = -E1 - self.Y[i1] * self.kernel(self.X[i1], self.X[i1]) * (alpha1_new-self.alpha[i1]) - self.Y[i2] \\\n",
    "                     * self.kernel(self.X[i2], self.X[i1]) * (alpha2_new-self.alpha[i2])+ self.b \n",
    "            b2_new = -E2 - self.Y[i1] * self.kernel(self.X[i1], self.X[i2]) * (alpha1_new-self.alpha[i1]) - self.Y[i2] \\\n",
    "                     * self.kernel(self.X[i2], self.X[i2]) * (alpha2_new-self.alpha[i2])+ self.b \n",
    "                                                                \n",
    "            if 0 < alpha1_new < self.C:\n",
    "                b_new = b1_new\n",
    "            elif 0 < alpha2_new < self.C:\n",
    "                b_new = b2_new\n",
    "            else:\n",
    "                b_new = (b1_new + b2_new) / 2\n",
    "            \n",
    "            #uodate the parameters\n",
    "            self.alpha[i1] = alpha1_new\n",
    "            self.alpha[i2] = alpha2_new\n",
    "            self.b = b_new\n",
    "            \n",
    "            self.E[i1] = self._E(i1)\n",
    "            self.E[i2] = self._E(i2)\n",
    "        return 'train done!'\n",
    "    \n",
    "    def predict(self, data):\n",
    "        r = self.b\n",
    "        for i in range(self.m):\n",
    "            r += self.alpha[i] * self.Y[i] * self.kernel(data, self.X[i])\n",
    "            \n",
    "        return 1 if r > 0 else -1\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        right_count = 0\n",
    "        for i in range(len(X_test)):\n",
    "            result = self.predict(X_test[i])\n",
    "            if result == y_test[i]:\n",
    "                right_count += 1\n",
    "        return right_count / len(X_test)\n",
    "    \n",
    "    def _weight(self):\n",
    "        # linear model\n",
    "        yx = self.Y.reshape(-1, 1)*self.X\n",
    "        self.w = np.dot(yx.T, self.alpha)\n",
    "        return self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVM(max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train done!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.svm.SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpu/anaconda3/envs/myLearning_36/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.svm.SVC\n",
    "\n",
    "*(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False,tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=None,random_state=None)*\n",
    "\n",
    "参数：\n",
    "\n",
    "- C：C-SVC的惩罚参数C?默认值是1.0\n",
    "\n",
    "C越大，相当于惩罚松弛变量，希望松弛变量接近0，即对误分类的惩罚增大，趋向于对训练集全分对的情况，这样对训练集测试时准确率很高，但泛化能力弱。C值小，对误分类的惩罚减小，允许容错，将他们当成噪声点，泛化能力较强。\n",
    "\n",
    "- kernel ：核函数，默认是rbf，可以是‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ \n",
    "    \n",
    "    – 线性：u'v\n",
    "    \n",
    "    – 多项式：(gamma*u'*v + coef0)^degree\n",
    "\n",
    "    – RBF函数：exp(-gamma|u-v|^2)\n",
    "\n",
    "    – sigmoid：tanh(gamma*u'*v + coef0)\n",
    "\n",
    "\n",
    "- degree ：多项式poly函数的维度，默认是3，选择其他核函数时会被忽略。\n",
    "\n",
    "\n",
    "- gamma ： ‘rbf’,‘poly’ 和‘sigmoid’的核函数参数。默认是’auto’，则会选择1/n_features\n",
    "\n",
    "\n",
    "- coef0 ：核函数的常数项。对于‘poly’和 ‘sigmoid’有用。\n",
    "\n",
    "\n",
    "- probability ：是否采用概率估计？.默认为False\n",
    "\n",
    "\n",
    "- shrinking ：是否采用shrinking heuristic方法，默认为true\n",
    "\n",
    "\n",
    "- tol ：停止训练的误差值大小，默认为1e-3\n",
    "\n",
    "\n",
    "- cache_size ：核函数cache缓存大小，默认为200\n",
    "\n",
    "\n",
    "- class_weight ：类别的权重，字典形式传递。设置第几类的参数C为weight*C(C-SVC中的C)\n",
    "\n",
    "\n",
    "- verbose ：允许冗余输出？\n",
    "\n",
    "\n",
    "- max_iter ：最大迭代次数。-1为无限制。\n",
    "\n",
    "\n",
    "- decision_function_shape ：‘ovo’, ‘ovr’ or None, default=None3\n",
    "\n",
    "\n",
    "- random_state ：数据洗牌时的种子值，int值\n",
    "\n",
    "\n",
    "主要调节的参数有：C、kernel、degree、gamma、coef0。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
